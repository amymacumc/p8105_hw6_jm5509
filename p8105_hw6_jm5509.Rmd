---
title: "p8105_hw6_jm5509"
author: "Echo"
date: "2022-11-23"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(timeout = 6000)
library(tidyverse)
library(modelr)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
```

## Problem 1

Read the weather data:
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

## Problem 2

First read the data:
```{r}
homicides_df <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

Then I created a `city_state` variable and a binary variable `resolved` indicating whether the homicide is solved, and omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. I also limit my analysis those for whom `victim_race` is white or black. Be sure that `victim_age` is numeric. 

```{r}
homicides_tb <-  homicides_df %>% 
  mutate(city_state = str_c(city, state, sep = ', '),
        resolved = as.numeric(disposition == 'Closed by arrest') ) %>% 
  filter(city_state !=  'Dallas, TX' & city_state != 'Phoenix, AZ' &
           city_state !=  'Kansas City, MO') %>% 
  filter(city_state != 'Tulsa, AL') %>% 
  filter(victim_race == 'White' | victim_race == 'Black') %>% 
  mutate(victim_age = as.numeric(victim_age),
         victim_race = fct_relevel(victim_race, 'White')) 
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with `resolved vs unresolved` as the outcome and `victim age`, `sex` and `race` as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
bal_logistic <- homicides_tb %>% 
  filter(city_state == 'Baltimore, MD') %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., 
      family = binomial())

bal_logistic %>% 
  broom::tidy(conf.int = TRUE) %>% 
  mutate(OR = exp(estimate),
         conf_low_OR = exp(conf.low),
         conf_high_OR = exp(conf.high)) %>% 
  select(term, OR, conf_low_OR, conf_high_OR) %>% 
  filter(term == 'victim_sexMale') %>% 
  knitr::kable(digits = 3)

```

Now I run glm for each of the cities in dataset, and extract the adjusted odds ratio (and CI) for solving homicides **comparing male victims to female victims**. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.
```{r}
all_cities <- homicides_tb %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
         models = map(models, broom::tidy, conf.int = TRUE)) %>% 
  select(-data) %>% 
  unnest() %>% 
  mutate(OR = exp(estimate),
         conf_low_OR = exp(conf.low),
         conf_high_OR = exp(conf.high)) %>% 
  select(city_state, term, OR, conf_low_OR, conf_high_OR) %>% 
  filter(term == 'victim_sexMale') 

all_cities %>% knitr::kable()
```


```{r}
all_cities %>% 
  ggplot(aes(x = fct_reorder(city_state, OR, .desc = TRUE), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf_low_OR, ymax = conf_high_OR)) +
  theme(text = element_text(size = 10),
          axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs( x = 'city', y ='odds Ratio',
    title = 'Estimated ORs and CIs for Each City\'s Unsolved Homicides'
  )
```

## Problem 3

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
bwt <- read_csv('birthweight.csv') %>% 
  mutate(
    babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform)
         )
bwt %>% is.na() %>% any()
```
There is no missing data in this `bwt` data frame.

Next, I would propose a regression model for `bwt`. I would first consider this model based on a hypothesized structure for the factors that underly `bwt`, and select the predictors of interest: `blength`,`babysex`,`bhead`, 
`delwt`, `frace`,`gaweeks`, `malform`, `menarche`,`momage`, `mrace`, `ppbmi`,`smoken`,`wtgain`.

First, I would make the following models and review these predictors' p-value.
```{r}
bwt %>%  lm(bwt ~ blength, data = .) %>% 
  broom::tidy()

bwt %>%  lm(bwt ~ babysex, data = .) %>% 
  broom::tidy()

bwt %>%  lm(bwt ~ bhead, data = .) %>% 
  broom::tidy()

bwt %>%  lm(bwt ~ blength * bhead * babysex, data = .) %>% 
  broom::tidy()
```

From the results above, we can observe that all the predictors have a p-value<0.05.
So Next, I would make the following models and review these adjusted R squared.
```{r}
bwt %>%  lm(bwt ~ blength, data = .) %>% 
  broom::glance()

bwt %>%  lm(bwt ~ babysex, data = .) %>% 
  broom::glance()

bwt %>%  lm(bwt ~ bhead, data = .) %>% 
  broom::glance()

bwt %>%  lm(bwt ~ blength * bhead * babysex, data = .) %>% 
  broom::glance()

```


In this case, the adjusted R squared of model using `babysex` as the only predictor is relatively low. Due to the rule of parsimony, I would exclude this predictor from my model.

In the end, my model would be:
```{r}
mdl1 <- bwt %>%  lm(bwt ~ blength * bhead, data = .) 
mdl1 %>% broom::tidy()
mdl1 %>% broom::glance()
```

Below is a plot of model residuals against fitted values.
```{r}
mdl1_resid <- add_residuals(bwt, mdl1)
mdl1_pred <- add_predictions(bwt, mdl1)
mdl1_full <- bwt %>% 
  mutate(resid = mdl1_resid$resid,
         pred = mdl1_pred$pred)
mdl1_full %>% ggplot(aes(x = pred, y = resid)) +
  geom_point() + geom_smooth() +
  labs(title = 'Residuals vs Fitted',
       x = 'fitted', y = 'residuals' )
```

In this plot, the range of residuals tends to decrease as the predicted `bwt` increases.

I would compare my model to two others:

1.using length at birth and gestational age as predictors (main effects only)
```{r}
mdl2 <- bwt %>% lm(bwt ~ blength + gaweeks, data = .)
mdl2 %>% broom::tidy()
mdl2 %>% broom::glance()
```

2.using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
mdl3 <- bwt %>% lm(bwt ~ bhead * blength * babysex , data = .)
mdl3 %>% broom::tidy()
mdl3 %>% broom::glance()

```

I would make this comparison among these models in terms of the cross-validated prediction error.

```{r}
cv_df <- crossv_mc(bwt, 100)
cv_df <- cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```
I now have many training and testing datasets, and I’d like to fit my candidate models above and assess prediction accuracy as I did for the single training / testing split. To do this, I’ll fit models and obtain RMSEs using `mutate` + `map` & `map2`.
```{r}
cv_df = 
  cv_df %>% 
  mutate(
    mdl1_fit = map(train, ~lm(bwt ~ blength * bhead, data = .x)),
    mdl2_fit = map(train, ~lm(bwt ~ blength + gaweeks,data = .x)),
    mdl3_fit = map(train, ~lm(bwt ~ bhead * blength * babysex , data = .x))
  ) %>% 
  mutate(
    rmse_mdl1 = map2_dbl(mdl1_fit, test, ~rmse(model = .x, data = .y)),
    rmse_mdl2 = map2_dbl(mdl2_fit, test, ~rmse(model = .x, data = .y)),
    rmse_mdl3 = map2_dbl(mdl3_fit, test, ~rmse(model = .x, data = .y))
  )
```

I’m mostly focused on RMSE as a way to compare these models, and the plot below shows the distribution of RMSE values for each candidate model.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = 'RMSE for Cross Validation',
       x = 'models', y = 'RMSE'
  )
```

From this RSME plot, it seems that the model1:`lm(bwt ~ blength * bhead)` and the model3:`lm(bwt ~ bhead * blength * babysex)` have better fit. The model 1 seems slightly better. Hence, it's better to contain `blength` and `bhead` in the model to predict babies' birthweight.






